import { Plugin, Notice, WorkspaceLeaf, TFile } from 'obsidian';
import { AIRecordingView, AI_RECORDING_VIEW_TYPE } from './ai-recording-view';
import { AIRecordingSettings, DEFAULT_SETTINGS, AIRecordingSettingTab } from './settings';
import { TranscriptionService } from './transcription-service';
import { SummaryService } from './summary-service';

export type RecordingState = 'IDLE' | 'RECORDING' | 'PAUSED' | 'FINISHED' | 'DELETED' | 'UPLOADING' | 'TRANSCRIBING' | 'SUMMARIZING';

export interface RecordingMetadata {
	id: string;
	title: string;
	date: string;
	duration: number;
	status: 'pending' | 'processing' | 'completed' | 'error';
	audioFile?: string;
	transcriptFile?: string;
	summaryFile?: string;
	segments: Array<{start: number, end: number}>;
	createdAt: number;
	updatedAt: number;
}

export default class AIRecordingPlugin extends Plugin {
	settings: AIRecordingSettings;
	sidebar: WorkspaceLeaf | null = null;
	recordingState: RecordingState = 'IDLE';
	recordingView: AIRecordingView | null = null;
	currentRecording: {
		id: string;
		startTime: Date;
		pausedTime: number;
		segments: Array<{start: number, end: number}>;
		audioBlob?: Blob;
		audioChunks: Blob[];
	} | null = null;
	mediaRecorder: MediaRecorder | null = null;
	audioStream: MediaStream | null = null;
	recordingsIndex: RecordingMetadata[] = [];
	recordingsFolder: string = 'AI Recordings';
	transcriptionService: TranscriptionService;
	summaryService: SummaryService;

	async onload() {
		console.log('Plugin AI Recording charg√©');
		
		// Charger les param√®tres
		await this.loadSettings();
		
		// Mettre √† jour le dossier d'enregistrements depuis les param√®tres
		this.recordingsFolder = this.settings.recordingsFolder;
		
		// Initialiser les services
		this.transcriptionService = new TranscriptionService();
		this.summaryService = new SummaryService();
		
		new Notice('Plugin AI Recording charg√© avec succ√®s');

		// Enregistrer la vue personnalis√©e
		this.registerView(AI_RECORDING_VIEW_TYPE, (leaf) => {
			this.recordingView = new AIRecordingView(leaf, this);
			return this.recordingView;
		});

		// Ajouter le bouton microphone dans le ribbon
		this.addRibbonIcon('mic', 'AI Recording', async () => {
			console.log('üé§ [DEBUG] Clic sur l\'ic√¥ne microphone d√©tect√©');
			await this.toggleSidebar();
		});

		// Ajouter l'onglet de param√®tres
		this.addSettingTab(new AIRecordingSettingTab(this.app, this));

		// Ajouter les commandes avec raccourcis clavier
		this.registerCommands();

		// Charger l'index des enregistrements apr√®s que le workspace soit pr√™t
		this.app.workspace.onLayoutReady(() => {
			console.log('Workspace ready, loading recordings index...');
			this.loadRecordingsIndex();
		});
	}

	registerCommands() {
		// Commande : Toggle Sidebar
		this.addCommand({
			id: 'toggle-sidebar',
			name: 'Ouvrir/Fermer la sidebar AI Recording',
			callback: async () => {
				await this.toggleSidebar();
			}
		});

		// Commande : Start Recording
		this.addCommand({
			id: 'start-recording',
			name: 'D√©marrer un enregistrement',
			callback: async () => {
				if (this.recordingState === 'IDLE') {
					const hasPermission = await this.checkMicrophonePermissions();
					if (!hasPermission) {
						const granted = await this.requestMicrophoneAccess();
						if (!granted) return;
					}
					this.setRecordingState('RECORDING');
					new Notice('Enregistrement d√©marr√©');
				} else {
					new Notice('Un enregistrement est d√©j√† en cours');
				}
			}
		});

		// Commande : Stop Recording
		this.addCommand({
			id: 'stop-recording',
			name: 'Terminer l\'enregistrement en cours',
			callback: () => {
				if (this.recordingState === 'RECORDING' || this.recordingState === 'PAUSED') {
					this.setRecordingState('FINISHED');
					new Notice('Enregistrement termin√©');
				} else {
					new Notice('Aucun enregistrement en cours');
				}
			}
		});

		// Commande : Pause/Resume Recording
		this.addCommand({
			id: 'pause-resume-recording',
			name: 'Pause/Reprendre l\'enregistrement',
			callback: () => {
				if (this.recordingState === 'RECORDING') {
					this.setRecordingState('PAUSED');
					new Notice('Enregistrement en pause');
				} else if (this.recordingState === 'PAUSED') {
					this.resumeRecording();
					this.setRecordingState('RECORDING');
					new Notice('Enregistrement repris');
				} else {
					new Notice('Aucun enregistrement en cours');
				}
			}
		});
	}

	async loadSettings() {
		this.settings = Object.assign({}, DEFAULT_SETTINGS, await this.loadData());
	}

	async saveSettings() {
		await this.saveData(this.settings);
		// Mettre √† jour le dossier d'enregistrements si chang√©
		this.recordingsFolder = this.settings.recordingsFolder;
	}

	onunload() {
		console.log('Plugin AI Recording d√©charg√©');
		if (this.sidebar) {
			this.app.workspace.detachLeavesOfType(AI_RECORDING_VIEW_TYPE);
		}
	}

	async createSidebar() {
		const { workspace } = this.app;
		
		console.log('üîç [DEBUG] createSidebar appel√©e');
		
		// V√©rifier l'√©tat de la sidebar droite et l'ouvrir si n√©cessaire
		// @ts-ignore
		const isRightSidebarCollapsed = workspace.rightSplit?.collapsed;
		console.log('üîç [DEBUG] Sidebar droite collapsed ?', isRightSidebarCollapsed);
		console.log('üîç [DEBUG] workspace.rightSplit existe ?', !!workspace.rightSplit);
		
		if (isRightSidebarCollapsed) {
			console.log('üîç [DEBUG] Tentative d\'ouverture de la sidebar droite...');
			// Ouvrir la sidebar droite si elle est ferm√©e
			// @ts-ignore
			this.app.commands.executeCommandById('app:toggle-right-sidebar');
			// Petit d√©lai pour laisser la sidebar s'ouvrir
			await new Promise(resolve => setTimeout(resolve, 100));
			console.log('üîç [DEBUG] Commande toggle-right-sidebar ex√©cut√©e');
		}
		
		// V√©rifier si une vue existe d√©j√†
		const existing = workspace.getLeavesOfType(AI_RECORDING_VIEW_TYPE);
		console.log('üîç [DEBUG] Vues existantes du plugin:', existing.length);
		
		if (existing.length > 0) {
			console.log('üîç [DEBUG] Vue existante trouv√©e, r√©v√©lation...');
			workspace.revealLeaf(existing[0]);
			this.sidebar = existing[0];
			console.log('üîç [DEBUG] Vue r√©v√©l√©e avec succ√®s');
			return;
		}
		
		// Cr√©er dans la sidebar droite
		console.log('üîç [DEBUG] Cr√©ation d\'un nouveau leaf...');
		const leaf = workspace.getRightLeaf(false);
		console.log('üîç [DEBUG] Leaf obtenu:', !!leaf);
		
		if (leaf) {
			console.log('üîç [DEBUG] Configuration du viewState...');
			await leaf.setViewState({
				type: AI_RECORDING_VIEW_TYPE,
				active: true,
			});
			console.log('üîç [DEBUG] ViewState configur√©, r√©v√©lation du leaf...');
			workspace.revealLeaf(leaf);
			this.sidebar = leaf;
			console.log('üîç [DEBUG] Sidebar cr√©√©e et r√©v√©l√©e avec succ√®s');
		} else {
			console.error('‚ùå [ERROR] Impossible d\'obtenir un leaf dans la sidebar droite');
		}
	}

	async toggleSidebar() {
		console.log('üîç [DEBUG] toggleSidebar appel√©e');
		await this.createSidebar();
	}

	getRecordingState(): RecordingState {
		return this.recordingState;
	}

	setRecordingState(state: RecordingState) {
		const previousState = this.recordingState;
		this.recordingState = state;
		
		// G√©rer les transitions d'√©tats
		this.handleStateTransition(previousState, state);
		this.updateSidebar();
	}

	handleStateTransition(from: RecordingState, to: RecordingState) {
		console.log(`Transition d'√©tat: ${from} ‚Üí ${to}`);
		
		switch (to) {
			case 'RECORDING':
				this.startNewRecording();
				break;
			case 'PAUSED':
				this.pauseRecording();
				break;
			case 'FINISHED':
				this.finishRecording();
				break;
			case 'DELETED':
				this.deleteRecording();
				break;
			case 'IDLE':
				this.resetToIdle();
				break;
		}
	}

	async startNewRecording() {
		try {
			// Demander les permissions microphone
			this.audioStream = await navigator.mediaDevices.getUserMedia({ 
				audio: {
					echoCancellation: true,
					noiseSuppression: true,
					autoGainControl: true
				}
			});

			// Cr√©er le MediaRecorder
			this.mediaRecorder = new MediaRecorder(this.audioStream, {
				mimeType: 'audio/webm;codecs=opus'
			});

			// Initialiser l'enregistrement
			this.currentRecording = {
				id: `recording_${Date.now()}`,
				startTime: new Date(),
				pausedTime: 0,
				segments: [],
				audioChunks: []
			};

			// Configurer les √©v√©nements MediaRecorder
			this.setupMediaRecorderEvents();

			// D√©marrer l'enregistrement
			this.mediaRecorder.start();
			new Notice('Enregistrement d√©marr√©');
		} catch (error) {
			console.error('Erreur lors du d√©marrage de l\'enregistrement:', error);
			new Notice(`Erreur: ${error.message}`);
			this.setRecordingState('IDLE');
		}
	}

	setupMediaRecorderEvents() {
		if (!this.mediaRecorder) return;

		this.mediaRecorder.ondataavailable = (event) => {
			if (event.data.size > 0 && this.currentRecording) {
				this.currentRecording.audioChunks.push(event.data);
			}
		};

		this.mediaRecorder.onstop = () => {
			if (this.currentRecording && this.currentRecording.audioChunks.length > 0) {
				this.currentRecording.audioBlob = new Blob(this.currentRecording.audioChunks, {
					type: 'audio/webm'
				});
				console.log('Audio blob cr√©√©:', this.currentRecording.audioBlob.size, 'bytes');
			}
		};

		this.mediaRecorder.onerror = (event) => {
			console.error('Erreur MediaRecorder:', event);
			new Notice('Erreur lors de l\'enregistrement audio');
			this.setRecordingState('IDLE');
		};
	}

	pauseRecording() {
		if (this.mediaRecorder && this.mediaRecorder.state === 'recording') {
			this.mediaRecorder.pause();
			
			if (this.currentRecording) {
				const now = new Date();
				const segmentStart = new Date(this.currentRecording.startTime.getTime() + this.currentRecording.pausedTime);
				this.currentRecording.segments.push({
					start: segmentStart.getTime(),
					end: now.getTime()
				});
			}
			new Notice('Enregistrement en pause');
		}
	}

	resumeRecording() {
		if (this.mediaRecorder && this.mediaRecorder.state === 'paused') {
			this.mediaRecorder.resume();
			
			if (this.currentRecording) {
				const now = new Date();
				this.currentRecording.pausedTime += now.getTime() - this.currentRecording.startTime.getTime();
			}
			new Notice('Enregistrement repris');
		}
	}

	async finishRecording() {
		if (this.mediaRecorder && this.currentRecording) {
			// Cr√©er une Promise qui attend que le blob soit cr√©√©
			const blobReady = new Promise<void>((resolve) => {
				if (this.mediaRecorder) {
					this.mediaRecorder.addEventListener('stop', () => {
						// Attendre un peu pour s'assurer que onstop a fini
						setTimeout(() => resolve(), 100);
					}, { once: true });
				}
			});
			
			// Arr√™ter l'enregistrement
			if (this.mediaRecorder.state === 'recording' || this.mediaRecorder.state === 'paused') {
				this.mediaRecorder.stop();
			}
			
			// Attendre que le blob soit cr√©√©
			await blobReady;
			
			// Fermer le stream audio
			if (this.audioStream) {
				this.audioStream.getTracks().forEach(track => track.stop());
				this.audioStream = null;
			}
			
			// Sauvegarder l'enregistrement
			const recordingId = await this.saveRecording();
			
			// Rafra√Æchir l'historique apr√®s sauvegarde
			this.updateSidebar();
			
			// Marquer l'enregistrement comme termin√©
			new Notice('Enregistrement termin√© et sauvegard√©');
			console.log('Enregistrement termin√©:', this.currentRecording);
			
			// D√©marrer la transcription si configur√©
			if (recordingId && this.settings.transcriptionProvider === 'openai') {
				await this.transcribeRecording(recordingId);
			}
		}
	}

	deleteRecording() {
		if (this.mediaRecorder && this.currentRecording) {
			// Arr√™ter l'enregistrement
			if (this.mediaRecorder.state === 'recording' || this.mediaRecorder.state === 'paused') {
				this.mediaRecorder.stop();
			}
			
			// Fermer le stream audio
			if (this.audioStream) {
				this.audioStream.getTracks().forEach(track => track.stop());
				this.audioStream = null;
			}
			
			// Supprimer l'enregistrement
			new Notice('Enregistrement supprim√©');
			console.log('Enregistrement supprim√©');
			
			// Revenir automatiquement √† IDLE pour permettre un nouvel enregistrement
			setTimeout(() => {
				this.setRecordingState('IDLE');
			}, 500); // Petit d√©lai pour que l'utilisateur voie le message de suppression
		}
	}

	resetToIdle() {
		// Nettoyer les ressources
		if (this.mediaRecorder) {
			this.mediaRecorder = null;
		}
		if (this.audioStream) {
			this.audioStream.getTracks().forEach(track => track.stop());
			this.audioStream = null;
		}
		this.currentRecording = null;
	}

	getCurrentRecording() {
		return this.currentRecording;
	}

	async checkMicrophonePermissions(): Promise<boolean> {
		try {
			const result = await navigator.permissions.query({ name: 'microphone' as PermissionName });
			return result.state === 'granted';
		} catch (error) {
			console.warn('Impossible de v√©rifier les permissions microphone:', error);
			return false;
		}
	}

	async requestMicrophoneAccess(): Promise<boolean> {
		try {
			const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
			// Fermer imm√©diatement le stream de test
			stream.getTracks().forEach(track => track.stop());
			return true;
		} catch (error) {
			console.error('Acc√®s microphone refus√©:', error);
			new Notice('Acc√®s au microphone refus√©. Veuillez autoriser l\'acc√®s dans les param√®tres du navigateur.');
			return false;
		}
	}

	getRecordingDuration(): number {
		if (!this.currentRecording) return 0;
		
		const now = new Date();
		const elapsed = now.getTime() - this.currentRecording.startTime.getTime() - this.currentRecording.pausedTime;
		return Math.max(0, elapsed);
	}

	async loadRecordingsIndex() {
		try {
			const indexFile = `${this.recordingsFolder}/recordings-index.json`;
			console.log('Loading recordings index from:', indexFile);
			
			const file = this.app.vault.getAbstractFileByPath(indexFile);
			
			if (file && file instanceof TFile) {
				const content = await this.app.vault.read(file);
				this.recordingsIndex = JSON.parse(content);
				console.log('Recordings index loaded successfully:', this.recordingsIndex.length, 'recordings');
			} else {
				console.log('Index file not found, rebuilding from audio files...');
				await this.rebuildRecordingsIndex();
			}
			
			// Mettre √† jour l'affichage si la vue est ouverte
			this.updateSidebar();
		} catch (error) {
			console.error('Erreur lors du chargement de l\'index:', error);
			this.recordingsIndex = [];
		}
	}

	async rebuildRecordingsIndex() {
		try {
			// Trouver tous les fichiers audio dans le dossier d'enregistrements
			const allFiles = this.app.vault.getFiles();
			console.log('Total files in vault:', allFiles.length);
			
			const audioFiles = allFiles.filter(f => 
				f.path.startsWith(this.recordingsFolder) && 
				f.path.endsWith('.webm')
			);
			
			console.log('Found audio files:', audioFiles.length);
			
			// Cr√©er des entr√©es d'index pour chaque fichier audio
			this.recordingsIndex = audioFiles.map(file => {
				const fileName = file.name.replace('.webm', '');
				const match = fileName.match(/Recording_(\d{4}-\d{2}-\d{2})_(\d{2}-\d{2}-\d{2})/);
				
				let date = new Date().toISOString().split('T')[0];
				let title = fileName;
				
				if (match) {
					date = match[1];
					title = `Enregistrement ${match[1]} ${match[2]}`;
				}
				
				return {
					id: `recording_${file.stat.ctime}`,
					title: title,
					date: date,
					duration: 0,
					status: 'completed' as const,
					audioFile: file.path,
					segments: [] as Array<{start: number, end: number}>,
					createdAt: file.stat.ctime,
					updatedAt: file.stat.mtime
				};
			});
			
			// Trier du plus r√©cent au plus ancien
			this.recordingsIndex.sort((a, b) => b.createdAt - a.createdAt);
			
			console.log('Rebuilt index with', this.recordingsIndex.length, 'recordings');
			
			// Sauvegarder l'index via l'API Obsidian
			if (this.recordingsIndex.length > 0) {
				await this.saveRecordingsIndex();
			}
		} catch (error) {
			console.error('Erreur lors de la reconstruction de l\'index:', error);
			this.recordingsIndex = [];
		}
	}

	async saveRecordingsIndex() {
		try {
			// Cr√©er le dossier s'il n'existe pas
			await this.ensureRecordingsFolder();
			
			const indexFile = `${this.recordingsFolder}/recordings-index.json`;
			const content = JSON.stringify(this.recordingsIndex, null, 2);
			
			const file = this.app.vault.getAbstractFileByPath(indexFile);
			if (file && file instanceof TFile) {
				await this.app.vault.modify(file, content);
			} else {
				await this.app.vault.create(indexFile, content);
			}
		} catch (error) {
			console.error('Erreur lors de la sauvegarde de l\'index:', error);
		}
	}

	async ensureRecordingsFolder() {
		const folder = this.app.vault.getAbstractFileByPath(this.recordingsFolder);
		if (!folder) {
			await this.app.vault.createFolder(this.recordingsFolder);
		}
	}

	async saveRecording(): Promise<string | null> {
		if (!this.currentRecording || !this.currentRecording.audioBlob) {
			console.error('Aucun enregistrement √† sauvegarder');
			return null;
		}

		try {
			// Cr√©er le dossier s'il n'existe pas
			await this.ensureRecordingsFolder();
			
			// G√©n√©rer les noms de fichiers
			const date = new Date();
			const dateStr = date.toISOString().split('T')[0]; // YYYY-MM-DD
			const timeStr = date.toTimeString().split(' ')[0].replace(/:/g, '-'); // HH-MM-SS
			const baseName = `Recording_${dateStr}_${timeStr}`;
			
			// Cr√©er le dossier par date
			const dateFolder = `${this.recordingsFolder}/${dateStr}`;
			await this.ensureDateFolder(dateFolder);
			
			// Sauvegarder le fichier audio
			const audioFileName = `${baseName}.webm`;
			const audioPath = `${dateFolder}/${audioFileName}`;
			
			// D√©couper le fichier si n√©cessaire
			const audioBlobs = await this.chunkAudioIfNeeded(this.currentRecording.audioBlob);
			
			if (audioBlobs.length === 1) {
				// Fichier unique
				await this.app.vault.createBinary(audioPath, await audioBlobs[0].arrayBuffer());
			} else {
				// Fichiers multiples
				for (let i = 0; i < audioBlobs.length; i++) {
					const chunkPath = `${dateFolder}/${baseName}_part${i + 1}.webm`;
					await this.app.vault.createBinary(chunkPath, await audioBlobs[i].arrayBuffer());
				}
			}
			
			// Cr√©er les m√©tadonn√©es
			const metadata: RecordingMetadata = {
				id: this.currentRecording.id,
				title: `Enregistrement ${dateStr} ${timeStr}`,
				date: dateStr,
				duration: this.getRecordingDuration(),
				status: 'completed',
				audioFile: audioPath,
				segments: this.currentRecording.segments,
				createdAt: Date.now(),
				updatedAt: Date.now()
			};
			
			// Ajouter √† l'index
			this.recordingsIndex.unshift(metadata); // Ajouter au d√©but (plus r√©cent)
			
			// Sauvegarder l'index
			await this.saveRecordingsIndex();
			
			console.log('Enregistrement sauvegard√©:', metadata);
			
			return this.currentRecording.id;
			
		} catch (error) {
			console.error('Erreur lors de la sauvegarde:', error);
			new Notice('Erreur lors de la sauvegarde de l\'enregistrement');
			return null;
		}
	}

	async ensureDateFolder(dateFolder: string) {
		const folder = this.app.vault.getAbstractFileByPath(dateFolder);
		if (!folder) {
			await this.app.vault.createFolder(dateFolder);
		}
	}

	async chunkAudioIfNeeded(audioBlob: Blob): Promise<Blob[]> {
		const maxSize = 25 * 1024 * 1024; // 25MB limite
		
		if (audioBlob.size <= maxSize) {
			return [audioBlob];
		}
		
		// Pour l'instant, on retourne le blob entier
		// TODO: Impl√©menter le d√©coupage r√©el des fichiers audio
		console.warn('Fichier audio volumineux d√©tect√©:', audioBlob.size, 'bytes');
		return [audioBlob];
	}

	getRecordingsIndex(): RecordingMetadata[] {
		return this.recordingsIndex;
	}

	async deleteRecordingFromIndex(recordingId: string) {
		try {
			// Trouver l'enregistrement dans l'index
			const recordingIndex = this.recordingsIndex.findIndex(r => r.id === recordingId);
			if (recordingIndex === -1) {
				console.error('Enregistrement non trouv√©:', recordingId);
				return;
			}
			
			const recording = this.recordingsIndex[recordingIndex];
			
			// Supprimer le fichier audio
			if (recording.audioFile) {
				const audioFile = this.app.vault.getAbstractFileByPath(recording.audioFile);
				if (audioFile) {
					await this.app.vault.delete(audioFile);
				}
			}
			
			// Supprimer de l'index
			this.recordingsIndex.splice(recordingIndex, 1);
			
			// Sauvegarder l'index mis √† jour
			await this.saveRecordingsIndex();
			
			new Notice('Enregistrement supprim√©');
			console.log('Enregistrement supprim√©:', recordingId);
			
		} catch (error) {
			console.error('Erreur lors de la suppression:', error);
			new Notice('Erreur lors de la suppression de l\'enregistrement');
		}
	}

	updateSidebar() {
		// Mettre √† jour l'affichage de la sidebar
		if (this.recordingView) {
			this.recordingView.updateDisplay();
		}
		console.log('√âtat d\'enregistrement:', this.recordingState);
		console.log('Nombre d\'enregistrements dans l\'index:', this.recordingsIndex.length);
	}

	async transcribeRecording(recordingId: string) {
		try {
			// Trouver l'enregistrement dans l'index
			const recording = this.recordingsIndex.find(r => r.id === recordingId);
			if (!recording) {
				console.error('Enregistrement non trouv√©:', recordingId);
				return;
			}

			// V√©rifier la cl√© API
			if (!this.settings.openaiApiKey || this.settings.openaiApiKey.trim() === '') {
				new Notice('Cl√© API OpenAI manquante. Veuillez la configurer dans les param√®tres.');
				recording.status = 'error';
				await this.saveRecordingsIndex();
				this.updateSidebar();
				return;
			}

			// Mettre √† jour le statut
			recording.status = 'processing';
			await this.saveRecordingsIndex();
			this.setRecordingState('UPLOADING');

			// Lire le fichier audio
			if (!recording.audioFile) {
				throw new Error('Fichier audio manquant');
			}

			const audioFile = this.app.vault.getAbstractFileByPath(recording.audioFile);
			if (!audioFile || !(audioFile instanceof TFile)) {
				throw new Error('Fichier audio introuvable');
			}

			const audioBuffer = await this.app.vault.readBinary(audioFile);
			const audioBlob = new Blob([audioBuffer], { type: 'audio/webm' });

			// Passer √† l'√©tat TRANSCRIBING
			this.setRecordingState('TRANSCRIBING');

			// Effectuer la transcription
			const result = await this.transcriptionService.transcribeAudio(
				audioBlob,
				{
					apiKey: this.settings.openaiApiKey,
					model: this.settings.transcriptionModel,
					language: this.settings.transcriptionLanguage,
					responseFormat: 'verbose_json'
				},
				(status) => {
					console.log('Transcription status:', status);
					if (this.recordingView) {
						this.recordingView.updateTranscriptionStatus(status);
					}
				}
			);

			// Sauvegarder la transcription
			await this.saveTranscription(recording, result.text, result.language);

			// Mettre √† jour le statut
			recording.status = 'completed';
			await this.saveRecordingsIndex();
			
			new Notice('Transcription termin√©e avec succ√®s !');
			console.log('Transcription compl√©t√©e:', result);

			// D√©marrer la g√©n√©ration du r√©sum√© si configur√©
			if (this.settings.summaryProvider === 'openai') {
				await this.generateSummary(recordingId, result.text);
			} else {
				// Retour √† l'√©tat IDLE si pas de r√©sum√©
				this.setRecordingState('IDLE');
				this.updateSidebar();
			}

		} catch (error) {
			console.error('Erreur lors de la transcription:', error);
			new Notice(`Erreur de transcription: ${error.message}`);
			
			// Mettre √† jour le statut d'erreur
			const recording = this.recordingsIndex.find(r => r.id === recordingId);
			if (recording) {
				recording.status = 'error';
				await this.saveRecordingsIndex();
			}

			// Retour √† l'√©tat IDLE
			this.setRecordingState('IDLE');
			this.updateSidebar();
		}
	}

	async saveTranscription(recording: RecordingMetadata, transcriptText: string, language?: string) {
		try {
			// Cr√©er le nom de fichier pour la transcription
			const audioPath = recording.audioFile || '';
			const transcriptPath = audioPath.replace('.webm', '.md');
			
			// Cr√©er le contenu de la transcription
			const content = `# Transcription - ${recording.title}

**Date:** ${recording.date}
**Dur√©e:** ${this.formatDuration(recording.duration)}
${language ? `**Langue:** ${language}` : ''}

---

${transcriptText}
`;

			// Sauvegarder le fichier de transcription
			const existingFile = this.app.vault.getAbstractFileByPath(transcriptPath);
			if (existingFile && existingFile instanceof TFile) {
				await this.app.vault.modify(existingFile, content);
			} else {
				await this.app.vault.create(transcriptPath, content);
			}

			// Mettre √† jour les m√©tadonn√©es
			recording.transcriptFile = transcriptPath;
			recording.updatedAt = Date.now();
			await this.saveRecordingsIndex();

			console.log('Transcription sauvegard√©e:', transcriptPath);

		} catch (error) {
			console.error('Erreur lors de la sauvegarde de la transcription:', error);
			throw error;
		}
	}

	formatDuration(milliseconds: number): string {
		const minutes = Math.floor(milliseconds / 60000);
		const seconds = Math.floor((milliseconds % 60000) / 1000);
		return `${minutes}:${seconds.toString().padStart(2, '0')}`;
	}

	async generateAITitle(recordingId: string, transcriptText: string) {
		try {
			const recording = this.recordingsIndex.find(r => r.id === recordingId);
			if (!recording) return;

			// G√©n√©rer le titre AI en 3 mots
			const aiTitle = await this.summaryService.generateShortTitle(
				transcriptText,
				this.settings.openaiApiKey,
				'gpt-4o-mini'
			);

			// Utiliser la dur√©e de l'enregistrement au format MM:SS
			const durationStr = this.formatDuration(recording.duration);

			// Nouveau format: "Titre AI - MM:SS"
			recording.title = `${aiTitle} - ${durationStr}`;
			recording.updatedAt = Date.now();
			
			await this.saveRecordingsIndex();
			this.updateSidebar();
			
			console.log('Titre AI g√©n√©r√©:', recording.title);
		} catch (error) {
			console.error('Erreur lors de la g√©n√©ration du titre AI:', error);
			// On continue sans bloquer en cas d'erreur
		}
	}

	async generateSummary(recordingId: string, transcriptText: string) {
		try {
			// Trouver l'enregistrement dans l'index
			const recording = this.recordingsIndex.find(r => r.id === recordingId);
			if (!recording) {
				console.error('Enregistrement non trouv√©:', recordingId);
				return;
			}

			// V√©rifier la cl√© API
			if (!this.settings.openaiApiKey || this.settings.openaiApiKey.trim() === '') {
				new Notice('Cl√© API OpenAI manquante pour le r√©sum√©.');
				this.setRecordingState('IDLE');
				this.updateSidebar();
				return;
			}

			// Passer √† l'√©tat SUMMARIZING
			this.setRecordingState('SUMMARIZING');

			// Pr√©parer les variables pour le template
			const variables = {
				transcript: transcriptText,
				language: recording.transcriptFile ? 'd√©tect√©e' : 'non d√©tect√©e',
				datetime: new Date().toLocaleString('fr-FR'),
				duration: this.formatDuration(recording.duration),
				title: recording.title,
				date: recording.date
			};

			// G√©n√©rer le r√©sum√©
			const result = await this.summaryService.generateSummary(
				this.settings.summaryTemplate,
				variables,
				{
					apiKey: this.settings.openaiApiKey,
					model: this.settings.summaryModel,
					summaryLength: this.settings.summaryLength
				},
				(status) => {
					console.log('Summary status:', status);
					if (this.recordingView) {
						this.recordingView.updateTranscriptionStatus(status);
					}
				}
			);

			// Sauvegarder le r√©sum√©
			await this.saveSummary(recording, result.text);

			new Notice('R√©sum√© g√©n√©r√© avec succ√®s !');
			console.log('R√©sum√© compl√©t√©:', result);

			// G√©n√©rer le titre AI en 3 mots
			await this.generateAITitle(recordingId, transcriptText);

			// Retour √† l'√©tat IDLE
			this.setRecordingState('IDLE');
			this.updateSidebar();

		} catch (error) {
			console.error('Erreur lors de la g√©n√©ration du r√©sum√©:', error);
			new Notice(`Erreur de g√©n√©ration du r√©sum√©: ${error.message}`);
			
			// Retour √† l'√©tat IDLE
			this.setRecordingState('IDLE');
			this.updateSidebar();
		}
	}

	async saveSummary(recording: RecordingMetadata, summaryText: string) {
		try {
			// Cr√©er le nom de fichier pour le r√©sum√©
			const audioPath = recording.audioFile || '';
			const summaryPath = audioPath.replace('.webm', '_summary.md');
			
			// Cr√©er le contenu du r√©sum√©
			const content = `# R√©sum√© - ${recording.title}

**Date:** ${recording.date}
**Dur√©e:** ${this.formatDuration(recording.duration)}

---

${summaryText}
`;

			// Sauvegarder le fichier de r√©sum√©
			const existingFile = this.app.vault.getAbstractFileByPath(summaryPath);
			if (existingFile && existingFile instanceof TFile) {
				await this.app.vault.modify(existingFile, content);
			} else {
				await this.app.vault.create(summaryPath, content);
			}

			// Mettre √† jour les m√©tadonn√©es
			recording.summaryFile = summaryPath;
			recording.updatedAt = Date.now();
			await this.saveRecordingsIndex();

			console.log('R√©sum√© sauvegard√©:', summaryPath);

		} catch (error) {
			console.error('Erreur lors de la sauvegarde du r√©sum√©:', error);
			throw error;
		}
	}
}
